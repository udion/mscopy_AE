{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Encoder (E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resBlock(nn.Module):\n",
    "    def __init__(self, in_channels=64, out_channels=64, k=3, s=1, p=1):\n",
    "        super(resBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, k, stride=s, padding=p)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, k, stride=s, padding=p)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        return self.bn2(self.conv2(y)) + x\n",
    "    \n",
    "class resTransposeBlock(nn.Module):\n",
    "    def __init__(self, in_channels=64, out_channels=64, k=3, s=1, p=1):\n",
    "        super(resTransposeBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, k, stride=s, padding=p)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.ConvTranspose2d(out_channels, out_channels, k, stride=s, padding=p)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        return self.bn2(self.conv2(y)) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = resBlock(in_channels=3, out_channels=3, k=5, s=1, p=2)\n",
    "At = resTransposeBlock(in_channels=3, out_channels=3, k=5, s=1, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "i = torch.rand(1, 3, 32, 32)\n",
    "print(i.size())\n",
    "a = A(Variable(i))\n",
    "print(a.size())\n",
    "a = At(a)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, k=3, s=1, p=1, n_res_blocks=16):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_res_blocks = n_res_blocks\n",
    "        self.conv1 = nn.Conv2d(3, 64, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_1' + str(i+1), resBlock(in_channels=64, out_channels=64, k=k, s=s, p=p))\n",
    "        self.conv2 = nn.Conv2d(64, 32, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_2' + str(i+1), resBlock(in_channels=32, out_channels=32, k=k, s=s, p=p))\n",
    "        self.conv3 = nn.Conv2d(32, 8, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_3' + str(i+1), resBlock(in_channels=8, out_channels=8, k=k, s=s, p=p))\n",
    "        self.conv4 = nn.Conv2d(8, 1, k, stride=s, padding=p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_1'+str(i+1))(y)\n",
    "        y = self.conv2(y)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_2'+str(i+1))(y)\n",
    "        y = self.conv3(y)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_3'+str(i+1))(y)\n",
    "        y = self.conv4(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "E1 = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.9031 -0.3610  1.2018  ...   0.7953  0.0952 -0.7730\n",
       "  0.3095 -0.8629  0.6415  ...   0.8822  0.2406 -0.5124\n",
       "  0.8194  0.3846  0.2768  ...   0.0295  1.2961  0.0140\n",
       "           ...             ⋱             ...          \n",
       "  0.8982 -1.0420 -0.1356  ...   0.1664  0.0194 -1.0014\n",
       "  0.8625  0.2871 -1.4505  ...  -0.6737  1.0635 -0.8387\n",
       "  0.9252 -0.0480 -0.1523  ...  -0.8271  0.7355  0.8571\n",
       "[torch.FloatTensor of size 1x1x32x32]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E1(Variable(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, k=3, s=1, p=1, n_res_blocks=16):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_res_blocks = n_res_blocks\n",
    "        self.conv1 = nn.Conv2d(1, 8, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_1' + str(i+1), resBlock(in_channels=8, out_channels=8, k=k, s=s, p=p))\n",
    "        self.conv2 = nn.Conv2d(8, 32, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_2' + str(i+1), resBlock(in_channels=32, out_channels=32, k=k, s=s, p=p))\n",
    "        self.conv3 = nn.Conv2d(32, 64, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_3' + str(i+1), resBlock(in_channels=64, out_channels=64, k=k, s=s, p=p))\n",
    "        self.conv4 = nn.Conv2d(64, 3, k, stride=s, padding=p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_1'+str(i+1))(y)\n",
    "        y = self.conv2(y)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_2'+str(i+1))(y)\n",
    "        y = self.conv3(y)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_3'+str(i+1))(y)\n",
    "        y = self.conv4(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  1.0827 -0.0593 -0.0030  ...   1.0478  0.1732  0.2410\n",
       "  0.5288  0.6761 -0.2841  ...   1.1802  0.3283 -1.0316\n",
       "  0.6399 -1.9798 -0.0073  ...  -0.7257  0.4547 -0.4186\n",
       "           ...             ⋱             ...          \n",
       "  0.1903 -0.7642 -2.1776  ...  -0.6689  2.0894 -1.6200\n",
       " -0.3739 -1.4837 -1.6083  ...   0.9097 -0.8422 -0.9819\n",
       "  0.1924 -0.2091 -0.6234  ...  -0.0026 -0.5014 -0.2059\n",
       "\n",
       "(0 ,1 ,.,.) = \n",
       " -0.5666  0.0458  0.0823  ...  -0.1285 -0.1468  0.3786\n",
       " -0.0863  1.0000  0.1036  ...   0.5963  0.1359  0.7577\n",
       "  0.7004  0.3091 -1.3917  ...  -1.7849  1.3269 -0.1839\n",
       "           ...             ⋱             ...          \n",
       "  0.0722  0.7759  1.3589  ...  -1.3497  0.8703  0.8669\n",
       "  0.1839  0.4355 -0.0603  ...   1.7978  2.4161  1.7603\n",
       "  0.1993 -0.4282  0.1741  ...   1.2430  0.0179  0.5846\n",
       "\n",
       "(0 ,2 ,.,.) = \n",
       " -0.0520 -0.3354 -0.3922  ...   0.2921 -0.1066  0.3495\n",
       "  1.3898  0.7022  0.2357  ...  -0.5213  2.0845  0.8894\n",
       " -0.3942  0.3375  0.3673  ...  -0.8229 -1.2347  0.8303\n",
       "           ...             ⋱             ...          \n",
       "  0.3410 -0.3269  1.5709  ...  -1.7734  0.3023  0.1260\n",
       " -0.0174  1.9538  1.0620  ...   1.2324 -0.5406  0.9799\n",
       "  1.2128  1.3055  1.0436  ...   0.3352  0.2158  0.7104\n",
       "[torch.FloatTensor of size 1x3x32x32]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1(E1(Variable(i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
