{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Encoder (E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resBlock(nn.Module):\n",
    "    def __init__(self, in_channels=64, out_channels=64, k=3, s=1, p=1):\n",
    "        super(resBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, k, stride=s, padding=p)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, k, stride=s, padding=p)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        return self.bn2(self.conv2(y)) + x\n",
    "    \n",
    "class resTransposeBlock(nn.Module):\n",
    "    def __init__(self, in_channels=64, out_channels=64, k=3, s=1, p=1):\n",
    "        super(resTransposeBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, k, stride=s, padding=p)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.ConvTranspose2d(out_channels, out_channels, k, stride=s, padding=p)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        return self.bn2(self.conv2(y)) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = resBlock(in_channels=3, out_channels=3, k=5, s=1, p=2)\n",
    "At = resTransposeBlock(in_channels=3, out_channels=3, k=5, s=1, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "i = torch.rand(1, 3, 32, 32)\n",
    "print(i.size())\n",
    "a = A(Variable(i))\n",
    "print(a.size())\n",
    "a = At(a)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E(nn.Module):\n",
    "    def __init__(self, k=3, s=1, p=1, n_res_blocks=16):\n",
    "        super(E, self).__init__()\n",
    "        self.n_res_blocks = n_res_blocks\n",
    "        self.conv1 = nn.Conv2d(3, 64, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_1' + str(i+1), resBlock(in_channels=64, out_channels=64, k=k, s=s, p=p))\n",
    "        self.conv2 = nn.Conv2d(64, 32, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_2' + str(i+1), resBlock(in_channels=32, out_channels=32, k=k, s=s, p=p))\n",
    "        self.conv3 = nn.Conv2d(32, 8, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_3' + str(i+1), resBlock(in_channels=8, out_channels=8, k=k, s=s, p=p))\n",
    "        self.conv4 = nn.Conv2d(8, 1, k, stride=s, padding=p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_1'+str(i+1))(y)\n",
    "        y = self.conv2(y)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_2'+str(i+1))(y)\n",
    "        y = self.conv3(y)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_3'+str(i+1))(y)\n",
    "        y = self.conv4(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "E1 = E()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  1.7116 -0.1909  0.2748  ...   2.3927 -0.5373  0.0954\n",
       "  0.6214 -2.0303 -1.8899  ...  -0.2308 -1.1154 -0.0165\n",
       "  0.2596  0.2444 -1.9987  ...  -1.8513 -0.9425  0.3133\n",
       "           ...             ⋱             ...          \n",
       "  0.6772  1.4138 -0.5727  ...   1.5234  0.8912  0.0269\n",
       "  0.6772 -0.1078 -2.5094  ...   0.0764 -0.3250 -1.0620\n",
       "  1.6443  1.4955  0.7867  ...   0.0401 -0.4311 -0.2909\n",
       "[torch.FloatTensor of size 1x1x32x32]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E1(Variable(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    def __init__(self, k=3, s=1, p=1, n_res_blocks=16):\n",
    "        super(D, self).__init__()\n",
    "        self.n_res_blocks = n_res_blocks\n",
    "        self.conv1 = nn.Conv2d(1, 8, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_1' + str(i+1), resBlock(in_channels=8, out_channels=8, k=k, s=s, p=p))\n",
    "        self.conv2 = nn.Conv2d(8, 32, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_2' + str(i+1), resBlock(in_channels=32, out_channels=32, k=k, s=s, p=p))\n",
    "        self.conv3 = nn.Conv2d(32, 64, k, stride=s, padding=p)\n",
    "        for i in range(n_res_blocks):\n",
    "            self.add_module('residual_block_3' + str(i+1), resBlock(in_channels=64, out_channels=64, k=k, s=s, p=p))\n",
    "        self.conv4 = nn.Conv2d(64, 3, k, stride=s, padding=p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_1'+str(i+1))(y)\n",
    "        y = self.conv2(y)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_2'+str(i+1))(y)\n",
    "        y = self.conv3(y)\n",
    "        for i in range(self.n_res_blocks):\n",
    "            y = self.__getattr__('residual_block_3'+str(i+1))(y)\n",
    "        y = self.conv4(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.4352  1.3713  2.1673  ...  -0.2854 -0.5704  0.5093\n",
       " -0.1276  2.6184 -1.0822  ...   3.1426  2.7637 -0.5459\n",
       " -1.4393 -1.0901 -1.0960  ...   0.1455 -0.9688 -0.4661\n",
       "           ...             ⋱             ...          \n",
       "  0.2317  1.0995  0.6195  ...   2.5308 -0.3304 -0.5466\n",
       "  0.2395  2.0903 -2.6870  ...  -0.4819 -0.3337 -1.3960\n",
       "  0.4094  1.9413 -0.6637  ...   0.5250  1.0122  0.2618\n",
       "\n",
       "(0 ,1 ,.,.) = \n",
       " -1.2391  0.4855 -1.4408  ...   1.4412 -0.4702  0.5231\n",
       " -0.8185  0.3060  1.1245  ...  -0.9661  0.2471  1.5891\n",
       " -0.3648 -1.8255  0.1077  ...   0.3283  1.2629 -0.6357\n",
       "           ...             ⋱             ...          \n",
       " -1.4454 -0.8811  0.5056  ...  -0.5971 -0.5191  0.0851\n",
       "  0.9704 -1.2024 -0.1784  ...  -0.7417 -1.3928 -0.5833\n",
       " -0.7808 -0.0429 -1.0189  ...  -0.1904 -0.5911 -0.1119\n",
       "\n",
       "(0 ,2 ,.,.) = \n",
       " -0.4048 -0.5498  0.8187  ...   1.3329  0.0170  0.1075\n",
       "  2.0861  1.7548  1.5858  ...   1.4168  1.8486  1.5469\n",
       "  0.9424 -0.4886  4.6423  ...  -0.3712  1.4002  0.3525\n",
       "           ...             ⋱             ...          \n",
       " -0.3350 -0.9890  0.4384  ...   0.6537  1.5718  0.2150\n",
       " -0.3188 -0.2859  1.4946  ...   2.6412  1.6662  0.2463\n",
       " -0.3841  0.3377  1.1430  ...   2.2318  1.1696  0.7952\n",
       "[torch.FloatTensor of size 1x3x32x32]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1(E1(Variable(i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
